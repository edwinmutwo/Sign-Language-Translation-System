{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bbedb7-f817-4fb1-b1ed-a92c4fde40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pyttsx3\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2eebd-d208-4cd4-97ff-4a96915b8475",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5e7b12-f0e8-4195-ad81-b2957703abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462be278-2c03-4bb7-aa67-b28ac9f22117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f45abb-d088-4229-83ba-a5068ee12a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks_B(image, results):\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness = 2,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness = 2,circle_radius=3),\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,255), thickness = 2,circle_radius=1)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b3697-ff3e-41e1-9b38-4dedcf6bed4f",
   "metadata": {},
   "source": [
    "## Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20da807-b757-494d-acf0-063246071697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    rate = engine.getProperty('rate')\n",
    "    engine.setProperty('rate', 150)\n",
    "\n",
    "    #Setting the voice\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "    #Text input\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2ee3b-78eb-45e1-afbe-b3352d017ed1",
   "metadata": {},
   "source": [
    "# Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94cf1649-4292-4cd8-977f-1bdc3fef8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('MP_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7faf98a2-fa73-4494-bbd5-f681d94103e0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello 0.9999657268983247\n",
      "Hello 0.9999964387620707\n",
      "Hello 0.9999938267916962\n",
      "my 0.9999986711475534\n",
      "my 0.9999967667215448\n",
      "my 0.9999987955608677\n",
      "name 0.9970387378289353\n",
      "name 0.9969868145890246\n",
      "name 0.9983379958747839\n",
      "M 0.9713125747468784\n",
      "M 0.9954936668621857\n",
      "M 0.9987286677827197\n",
      "A 0.9987014875455064\n",
      "A 0.9984676982477733\n",
      "A 0.9980880931713607\n",
      "R 0.9911073195217939\n",
      "R 0.990281960726527\n",
      "R 0.9865951438350794\n",
      "K 0.997139360265801\n",
      "K 0.9996080422314948\n",
      "K 0.9991305253917347\n",
      "J 0.8708713447935988\n",
      "nice 0.9284893663275409\n",
      "nice 0.9952333700268422\n",
      "nice 0.9999190133814847\n",
      "to meet you 0.9934518557223584\n",
      "to meet you 0.9999999991269195\n",
      "to meet you 0.9999999999822773\n",
      "A 0.9984156126443413\n",
      "A 0.9980589704691918\n",
      "A 0.9990282845800409\n",
      "B 0.9985073672424052\n",
      "B 0.9996621670160983\n",
      "B 0.9997572602119823\n",
      "C 0.993714151258858\n",
      "C 0.9971920507279702\n",
      "C 0.9987465984532358\n",
      "D 0.9999969992891117\n",
      "D 0.9999929873099627\n",
      "D 0.9999924566876404\n",
      "E 0.9882888897467079\n",
      "E 0.9895766325321633\n",
      "E 0.9974376969804032\n",
      "F 0.9970178781155593\n",
      "F 0.9997363170308398\n",
      "F 0.9996534853558932\n",
      "G 0.9999691906732665\n",
      "G 0.9982728952901815\n",
      "G 0.9997422302431699\n",
      "H 0.9561405718917008\n",
      "H 0.97618265548443\n",
      "H 0.9756020987802768\n",
      "O 0.9092212511521751\n",
      "I 0.9993544638434488\n",
      "I 0.99954595782535\n",
      "I 0.9996304592688057\n",
      "J 0.9958168832073692\n",
      "J 0.9999618831841036\n",
      "J 0.9999386443659158\n",
      "K 0.9982559988761436\n",
      "K 0.9998938320230782\n",
      "K 0.9998019616999972\n",
      "L 0.9996998782731151\n",
      "L 0.9990347771136164\n",
      "L 0.9996236899456586\n",
      "M 0.9992357633916565\n",
      "M 0.9988862383920523\n",
      "M 0.998841947772937\n",
      "N 0.9497296245335026\n",
      "N 0.8809901311957232\n",
      "N 0.8088625796282891\n",
      "O 0.9993338496741921\n",
      "O 0.9997992261907093\n",
      "O 0.99994126139968\n",
      "Q 0.9788527686597497\n",
      "Q 0.9339486766846352\n",
      "P 0.9812784081770142\n",
      "P 0.9975194934316455\n",
      "P 0.9996955251204904\n",
      "Q 0.9895302999903909\n",
      "Q 0.9942579568198712\n",
      "Q 0.9977578521072548\n",
      "Q 0.9993545545031803\n",
      "Q 0.9997950544474341\n",
      "R 0.9817154606103884\n",
      "R 0.9787792996550706\n",
      "R 0.9534061116155726\n",
      "R 0.9738510055189679\n",
      "R 0.9714476227686082\n",
      "S 0.8180928121336745\n",
      "S 0.9999275225940849\n",
      "S 0.9998724606543121\n",
      "T 0.9962407273328292\n",
      "T 0.9991655548265373\n",
      "T 0.9978915538757789\n",
      "U 0.9917168123414715\n",
      "U 0.9998975947008292\n",
      "U 0.999870676834504\n",
      "V 0.9910684031196383\n",
      "V 0.9890541231770595\n",
      "V 0.9741896833663278\n",
      "W 0.998613408311257\n",
      "W 0.999467236961116\n",
      "W 0.9996532969298374\n",
      "X 0.8102835861675682\n",
      "X 0.9140533634506005\n",
      "X 0.9617253889013838\n",
      "Y 0.9676341316322502\n",
      "Y 0.998754833365658\n",
      "Y 0.9963352036853039\n",
      "Y 0.9890511493294355\n",
      "S 0.9693134103352911\n",
      "S 0.8742526474895587\n",
      "Z 0.999933901920151\n",
      "Z 0.9999509007581373\n",
      "Q 0.9986896674076248\n",
      "Z 0.994579935300543\n",
      "Z 0.9857491379848321\n",
      "Z 0.9780553129394036\n"
     ]
    }
   ],
   "source": [
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.8\n",
    "#minimum number of predictions for confirmation\n",
    "pr = 3\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "               \n",
    "        #draw landmarks\n",
    "        #draw_landmarks(image, results)\n",
    "        draw_styled_landmarks_B(image, results)\n",
    "        \n",
    "        #Export Cordinates\n",
    "        try:\n",
    "             #Extract hand and face  landmarks\n",
    "            lh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3))\n",
    "            rh_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3))\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3))\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3))\n",
    "            \n",
    "            #Concatenate rows\n",
    "            row = lh_row + rh_row + face_row + pose_row\n",
    "            \n",
    "            #Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            sign_class = model.predict(X)[0]\n",
    "            sign_prob = model.predict_proba(X)[0]\n",
    "                        \n",
    "            #Sentence Logic\n",
    "            if sign_prob[np.argmax(sign_prob)] > threshold:\n",
    "                predictions.append(sign_class)\n",
    "                print(sign_class, sign_prob[np.argmax(sign_prob)])\n",
    "                if predictions[-pr:] == [sign_class]*pr:\n",
    "                    if len(sentence) > 0:\n",
    "                        if sign_class != sentence[-1]:\n",
    "                            sentence.append(sign_class)\n",
    "                            speak(sign_class)\n",
    "                    else:\n",
    "                        sentence.append(sign_class)\n",
    "                        speak(sign_class)\n",
    "                    \n",
    "            \n",
    "            if len(sentence) > 5:\n",
    "                    sentence = sentence[-5:]\n",
    "            \n",
    "            cv2.rectangle(image, (0,0), (640,40),(0,0,0), -1 )\n",
    "            cv2.putText(image,  ' '.join(sentence), (3,30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "        \n",
    "        #break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31be636-57fb-439f-970a-2e3fef35f000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBMAI2",
   "language": "python",
   "name": "ibmai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
